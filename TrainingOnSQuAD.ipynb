{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainingOnSQuAD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kzafeiroudi/QuestRecommend/blob/master/TrainingOnSQuAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T7li7mODkIH7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifying the questions\n",
        "\n",
        "In this section, we are going to train a Random Forest classifier, in order to check whether the vector representation of the questions that we picked is good enough to train a model to identify the topic a question belongs to."
      ]
    },
    {
      "metadata": {
        "id": "icpMUi0VkgBA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload the dataset\n",
        "\n",
        "Upload the file `squad_vectors.csv` that will be used in this Python 3 notebook."
      ]
    },
    {
      "metadata": {
        "id": "9kIU11_UkmKS",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "21bcb3a2-71cf-4d89-aaa3-8dcb7b3d5cd3"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Choose from your own machine the files to upload - name should be \n",
        "# \"squad_vector.csv\"\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5269ee90-2d61-4ad6-ae6b-cc2f5b9559f2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5269ee90-2d61-4ad6-ae6b-cc2f5b9559f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving squad_vectors.csv to squad_vectors.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_ct9SE-UkzvE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download all important packages\n",
        "\n",
        "We will be using the **Weka** machine learning software through a Python wrapper. The following commands are necessary to install the packages before we use the software."
      ]
    },
    {
      "metadata": {
        "id": "VAa1G6CYH8Mh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pygraphviz\n",
        "!wget https://anaconda.org/anaconda/pygraphviz/1.3/download/linux-64/pygraphviz-1.3-py36h14c3975_1.tar.bz2\n",
        "!tar xvjf pygraphviz-1.3-py36h14c3975_1.tar.bz2\n",
        "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "\n",
        "import pygraphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJ9I4XzSICOs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Install deps from \n",
        "# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n",
        "apt-get update\n",
        "apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n",
        "nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n",
        "libopenal-dev timidity libwildmidi-dev unzip\n",
        "\n",
        "# Boost libraries\n",
        "apt-get install libboost-all-dev\n",
        "\n",
        "# Lua binding dependencies\n",
        "apt-get install liblua5.1-dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNRFg8wbk7bJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "28882cc1-a8a9-4995-95be-eaac12b427da"
      },
      "cell_type": "code",
      "source": [
        "import os       #importing os to set environment variable\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.2\" 2019-01-15\n",
            "OpenJDK Runtime Environment (build 11.0.2+9-Ubuntu-3ubuntu118.04.3)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.2+9-Ubuntu-3ubuntu118.04.3, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aD_Nzlesk_9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install libproj-dev proj-data proj-bin\n",
        "!apt-get install libgeos-dev\n",
        "!pip install cython\n",
        "!pip install python-weka-wrapper3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dlpy7OLTlL5y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Python libraries"
      ]
    },
    {
      "metadata": {
        "id": "rT46XG4qlNIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "190f957a-a04d-4765-d48f-0fedc842c7a8"
      },
      "cell_type": "code",
      "source": [
        "import weka.core.jvm as jvm\n",
        "jvm.start()\n",
        "\n",
        "from weka.core.converters import Loader, Saver\n",
        "from weka.core.classes import Random\n",
        "from weka.classifiers import Classifier, Evaluation\n",
        "from weka.core.dataset import Instances, Instance, Attribute\n",
        "from weka.filters import Filter\n",
        "from weka.attribute_selection import ASSearch, ASEvaluation, AttributeSelection\n",
        "from weka.clusterers import Clusterer, ClusterEvaluation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:weka.core.jvm:Adding bundled jars\n",
            "DEBUG:weka.core.jvm:Classpath=['/usr/local/lib/python3.6/dist-packages/javabridge/jars/rhino-1.7R4.jar', '/usr/local/lib/python3.6/dist-packages/javabridge/jars/runnablequeue.jar', '/usr/local/lib/python3.6/dist-packages/javabridge/jars/cpython.jar', '/usr/local/lib/python3.6/dist-packages/weka/lib/weka.jar', '/usr/local/lib/python3.6/dist-packages/weka/lib/python-weka-wrapper.jar']\n",
            "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
            "DEBUG:weka.core.jvm:Package support disabled\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "broGqycPncyZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the dataset `squad_vector.csv`\n",
        "\n",
        "We will first train a tree classifier (RandomForest) on the question vector representation that we have calculated."
      ]
    },
    {
      "metadata": {
        "id": "jJu6jTXVIIVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15be3a03-92fe-4f33-c7bb-9bd567c3cedc"
      },
      "cell_type": "code",
      "source": [
        "loader = Loader(classname=\"weka.core.converters.CSVLoader\")\n",
        "data_file = 'squad_vectors.csv'\n",
        "data = loader.load_file(data_file)\n",
        "\n",
        "print('Sample size: ', data.num_instances)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample size:  3111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z0HSR1FIn8l0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the classifier\n",
        "\n",
        "We choose to classify on the nominal atrribute **Class**. We first split our dataset to train and test, with a 66% to the train split.\n",
        "\n",
        "For the J48 classifier, which generated a pruned C4.5 decision tree, we have chosen a confidence factor used for pruning of 0.25.\n",
        "\n",
        "The resulting decision tree can be seen in the standard output."
      ]
    },
    {
      "metadata": {
        "id": "jkFUCI6LoFM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1edad313-95a2-4e88-d22c-1fa13addaa53"
      },
      "cell_type": "code",
      "source": [
        "print('Classifying on: ', data.attribute(0))\n",
        "data.class_index = 0\n",
        "train, test = data.train_test_split(66.0, Random(1))\n",
        "\n",
        "\n",
        "cls = Classifier(classname=\"weka.classifiers.trees.RandomForest\")\n",
        "cls.build_classifier(train)\n",
        "\n",
        "print(cls)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifying on:  @attribute Class {Super_Bowl_50,Warsaw,Normans,Nikola_Tesla,Computational_complexity_theory,Teacher,Martin_Luther,Southern_California,Sky_(United_Kingdom),Victoria_(Australia),Huguenot,Steam_engine,Oxygen,1973_oil_crisis,Apollo_program,European_Union_law,Amazon_rainforest,Ctenophora,'Fresno,_California',Packet_switching,Black_Death,Geology,Newcastle_upon_Tyne,Victoria_and_Albert_Museum,American_Broadcasting_Company,Genghis_Khan,Pharmacy,Immune_system,Civil_disobedience,Construction}\n",
            "RandomForest\n",
            "\n",
            "Bagging with 100 iterations and base learner\n",
            "\n",
            "weka.classifiers.trees.RandomTree -K 0 -M 1.0 -V 0.001 -S 1 -do-not-check-capabilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VBQ7NyxvoZZu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating the classifier\n",
        "\n",
        "We evaluate the trained model against the test split."
      ]
    },
    {
      "metadata": {
        "id": "4-gkfkpmoSn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c21c47d1-e94c-4dd3-cf80-95d935f06906"
      },
      "cell_type": "code",
      "source": [
        "evl = Evaluation(train)\n",
        "evl.test_model(cls, test)\n",
        "print(evl.summary(\"=== Percentage split 66% ===\"))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Correctly Classified Instances         762               72.0227 %\n",
            "Incorrectly Classified Instances       296               27.9773 %\n",
            "Kappa statistic                          0.7105\n",
            "Mean absolute error                      0.0495\n",
            "Root mean squared error                  0.1453\n",
            "Relative absolute error                 76.8582 %\n",
            "Root relative squared error             80.931  %\n",
            "Total Number of Instances             1058     \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HjWgJWj5rhVV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train another classifier\n",
        "\n",
        "In this case, we are training the same tree classifier (Random Forest) using 10-fold cross-validation"
      ]
    },
    {
      "metadata": {
        "id": "soThYzz8o4IX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5924c7d1-3730-4fab-93bd-dbd11cc8ca79"
      },
      "cell_type": "code",
      "source": [
        "# Choose Random Forest as the classifier\n",
        "classifier = Classifier(classname=\"weka.classifiers.trees.RandomForest\")\n",
        "\n",
        "# Randomize the data\n",
        "folds = 10\n",
        "rnd = Random(1)\n",
        "rand_data = Instances.copy_instances(data)\n",
        "rand_data.randomize(rnd)\n",
        "rand_data.stratify(folds)\n",
        "\n",
        "# Perform cross-validation and add predictions\n",
        "predicted_data = None\n",
        "evaluation = Evaluation(rand_data)\n",
        "for i in range(folds):\n",
        "  train = rand_data.train_cv(folds, i)\n",
        "  test = rand_data.test_cv(folds, i)\n",
        "\n",
        "  # Build and evaluate the classifier\n",
        "  cls = Classifier.make_copy(cls)\n",
        "  cls.build_classifier(train)\n",
        "  evaluation.test_model(cls, test)\n",
        "\n",
        "  # Add predictions\n",
        "  addcls = Filter(\n",
        "    classname=\"weka.filters.supervised.attribute.AddClassification\",\n",
        "    options=[\"-classification\", \"-distribution\", \"-error\"])\n",
        "  addcls.set_property(\"classifier\", Classifier.make_copy(cls))\n",
        "  addcls.inputformat(train)\n",
        "  # Train the classifier\n",
        "  addcls.filter(train)\n",
        "  pred = addcls.filter(test)\n",
        "  if predicted_data is None:\n",
        "    predicted_data = Instances.template_instances(pred, 0)\n",
        "  for n in range(pred.num_instances):\n",
        "    predicted_data.add_instance(pred.get_instance(n))\n",
        "\n",
        "\n",
        "print(evaluation.summary(\"=== \" + str(folds) + \" -fold Cross-Validation ===\"))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== 10 -fold Cross-Validation ===\n",
            "Correctly Classified Instances        2296               73.8026 %\n",
            "Incorrectly Classified Instances       815               26.1974 %\n",
            "Kappa statistic                          0.729 \n",
            "Mean absolute error                      0.0476\n",
            "Root mean squared error                  0.1413\n",
            "Relative absolute error                 73.9209 %\n",
            "Root relative squared error             78.7353 %\n",
            "Total Number of Instances             3111     \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bRVP7WUZvrBP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Attribute selection\n",
        "\n",
        "In this section, we are going to pick 100 attributes that show the highest InfoGain in accordance to the Class feature."
      ]
    },
    {
      "metadata": {
        "id": "ePmVnHMjtkTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7177
        },
        "outputId": "a9186f17-6adb-433b-d029-5814dba27f79"
      },
      "cell_type": "code",
      "source": [
        "full = loader.load_file(data_file)\n",
        "full.class_index = 0\n",
        "search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"100\"])\n",
        "evaluation = ASEvaluation(\"weka.attributeSelection.InfoGainAttributeEval\")\n",
        "attsel = AttributeSelection()\n",
        "attsel.ranking(True)\n",
        "attsel.folds(2)\n",
        "attsel.crossvalidation(True)\n",
        "attsel.seed(42)\n",
        "attsel.search(search)\n",
        "attsel.evaluator(evaluation)\n",
        "attsel.select_attributes(full)\n",
        "print(\"# of selected sttributes: \" + str(attsel.number_attributes_selected))\n",
        "print(attsel.results_string)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of selected sttributes: 100\n",
            "\n",
            "\n",
            "=== Attribute Selection on all input data ===\n",
            "\n",
            "Search Method:\n",
            "\tAttribute ranking.\n",
            "\n",
            "Attribute Evaluator (supervised, Class (nominal): 1 Class):\n",
            "\tInformation Gain Ranking Filter\n",
            "\n",
            "Ranked attributes:\n",
            " 0.351    270 vector_269\n",
            " 0.319      6 vector_5\n",
            " 0.312    287 vector_286\n",
            " 0.263    285 vector_284\n",
            " 0.263     91 vector_90\n",
            " 0.261     89 vector_88\n",
            " 0.259    267 vector_266\n",
            " 0.253    215 vector_214\n",
            " 0.247    217 vector_216\n",
            " 0.245     30 vector_29\n",
            " 0.243    111 vector_110\n",
            " 0.242     59 vector_58\n",
            " 0.24      19 vector_18\n",
            " 0.24     272 vector_271\n",
            " 0.236     87 vector_86\n",
            " 0.233     66 vector_65\n",
            " 0.232    290 vector_289\n",
            " 0.231    174 vector_173\n",
            " 0.23     219 vector_218\n",
            " 0.229    156 vector_155\n",
            " 0.228    260 vector_259\n",
            " 0.223    278 vector_277\n",
            " 0.22     299 vector_298\n",
            " 0.219    218 vector_217\n",
            " 0.218    221 vector_220\n",
            " 0.218    289 vector_288\n",
            " 0.216    202 vector_201\n",
            " 0.212    125 vector_124\n",
            " 0.212    101 vector_100\n",
            " 0.211    181 vector_180\n",
            " 0.211    295 vector_294\n",
            " 0.209    123 vector_122\n",
            " 0.208    192 vector_191\n",
            " 0.208     52 vector_51\n",
            " 0.207      2 vector_1\n",
            " 0.206    205 vector_204\n",
            " 0.204     10 vector_9\n",
            " 0.199     81 vector_80\n",
            " 0.199     20 vector_19\n",
            " 0.196     41 vector_40\n",
            " 0.194    161 vector_160\n",
            " 0.192     15 vector_14\n",
            " 0.19     119 vector_118\n",
            " 0.188    262 vector_261\n",
            " 0.187     39 vector_38\n",
            " 0.186     62 vector_61\n",
            " 0.185    203 vector_202\n",
            " 0.181     93 vector_92\n",
            " 0.175    233 vector_232\n",
            " 0.174    293 vector_292\n",
            " 0.174     90 vector_89\n",
            " 0.172    198 vector_197\n",
            " 0.171    120 vector_119\n",
            " 0.167     44 vector_43\n",
            " 0.165    148 vector_147\n",
            " 0.164     83 vector_82\n",
            " 0.164     53 vector_52\n",
            " 0.161     49 vector_48\n",
            " 0.161    244 vector_243\n",
            " 0.159    297 vector_296\n",
            " 0.158    294 vector_293\n",
            " 0.157    234 vector_233\n",
            " 0.156    200 vector_199\n",
            " 0.155    128 vector_127\n",
            " 0.153     77 vector_76\n",
            " 0.153    224 vector_223\n",
            " 0.153    166 vector_165\n",
            " 0.153    276 vector_275\n",
            " 0.153    292 vector_291\n",
            " 0.152     79 vector_78\n",
            " 0.152    159 vector_158\n",
            " 0.151     28 vector_27\n",
            " 0.151     12 vector_11\n",
            " 0.151     76 vector_75\n",
            " 0.149     67 vector_66\n",
            " 0.149    251 vector_250\n",
            " 0.147     31 vector_30\n",
            " 0.146    275 vector_274\n",
            " 0.146    175 vector_174\n",
            " 0.145    207 vector_206\n",
            " 0.145     24 vector_23\n",
            " 0.145    257 vector_256\n",
            " 0.144    269 vector_268\n",
            " 0.144    240 vector_239\n",
            " 0.144     71 vector_70\n",
            " 0.144     38 vector_37\n",
            " 0.143     23 vector_22\n",
            " 0.142    231 vector_230\n",
            " 0.142    126 vector_125\n",
            " 0.142     86 vector_85\n",
            " 0.142    273 vector_272\n",
            " 0.142     36 vector_35\n",
            " 0.142    212 vector_211\n",
            " 0.142    220 vector_219\n",
            " 0.141    118 vector_117\n",
            " 0.141    213 vector_212\n",
            " 0.14     113 vector_112\n",
            " 0.14     165 vector_164\n",
            " 0.14     138 vector_137\n",
            " 0.14      51 vector_50\n",
            "\n",
            "Selected attributes: 270,6,287,285,91,89,267,215,217,30,111,59,19,272,87,66,290,174,219,156,260,278,299,218,221,289,202,125,101,181,295,123,192,52,2,205,10,81,20,41,161,15,119,262,39,62,203,93,233,293,90,198,120,44,148,83,53,49,244,297,294,234,200,128,77,224,166,276,292,79,159,28,12,76,67,251,31,275,175,207,24,257,269,240,71,38,23,231,126,86,273,36,212,220,118,213,113,165,138,51 : 100\n",
            "\n",
            "\n",
            "=== Attribute selection 2 fold cross-validation (stratified), seed: 42 ===\n",
            "\n",
            "average merit      average rank  attribute\n",
            " 0.252 +- 0.022        2   +- 1        205 vector_204\n",
            " 0.227 +- 0.019        5.5 +- 2.5      270 vector_269\n",
            " 0.216 +- 0.003        7   +- 2        267 vector_266\n",
            " 0.222 +- 0.008        7   +- 0        285 vector_284\n",
            " 0.215 +- 0.001        7   +- 1        192 vector_191\n",
            " 0.21  +- 0.011        8.5 +- 4.5       91 vector_90\n",
            " 0.244 +- 0.051        9   +- 8         89 vector_88\n",
            " 0.203 +- 0.001       10   +- 1        287 vector_286\n",
            " 0.205 +- 0.005       10.5 +- 0.5       30 vector_29\n",
            " 0.198 +- 0.003       13   +- 3        217 vector_216\n",
            " 0.207 +- 0.024       13   +- 7         20 vector_19\n",
            " 0.192 +- 0.004       15.5 +- 1.5       19 vector_18\n",
            " 0.19  +- 0.005       18.5 +- 3.5        6 vector_5\n",
            " 0.187 +- 0.006       19.5 +- 3.5      111 vector_110\n",
            " 0.187 +- 0.008       19.5 +- 5.5      202 vector_201\n",
            " 0.187 +- 0.009       20.5 +- 5.5       90 vector_89\n",
            " 0.184 +- 0.003       21   +- 1        215 vector_214\n",
            " 0.184 +- 0.005       21.5 +- 2.5       59 vector_58\n",
            " 0.186 +- 0.011       21.5 +- 8.5      174 vector_173\n",
            " 0.185 +- 0.013       23.5 +-11.5      272 vector_271\n",
            " 0.218 +- 0.052       23.5 +-21.5      260 vector_259\n",
            " 0.18  +- 0.005       24.5 +- 6.5      120 vector_119\n",
            " 0.178 +- 0.001       27   +- 1        219 vector_218\n",
            " 0.202 +- 0.041       29   +-25        224 vector_223\n",
            " 0.176 +- 0.006       29   +- 8         83 vector_82\n",
            " 0.175 +- 0.002       30   +- 3        156 vector_155\n",
            " 0.2   +- 0.04        31.5 +-26.5      299 vector_298\n",
            " 0.174 +- 0.003       32   +- 3        297 vector_296\n",
            " 0.174 +- 0.004       32.5 +- 5.5       53 vector_52\n",
            " 0.174 +- 0.003       32.5 +- 4.5       66 vector_65\n",
            " 0.172 +- 0.002       34.5 +- 3.5       87 vector_86\n",
            " 0.171 +- 0.003       35   +- 5        292 vector_291\n",
            " 0.171 +- 0.008       35.5 +-12.5      294 vector_293\n",
            " 0.171 +- 0.003       36.5 +- 4.5      244 vector_243\n",
            " 0.176 +- 0.016       37.5 +-19.5       44 vector_43\n",
            " 0.172 +- 0.013       38.5 +-19.5       49 vector_48\n",
            " 0.167 +- 0.004       41.5 +- 5.5      200 vector_199\n",
            " 0.164 +- 0.004       47   +- 7        221 vector_220\n",
            " 0.165 +- 0.005       47   +- 8        276 vector_275\n",
            " 0.164 +- 0.003       48   +- 5        234 vector_233\n",
            " 0.164 +- 0.003       48.5 +- 7.5      289 vector_288\n",
            " 0.163 +- 0.001       49   +- 1        218 vector_217\n",
            " 0.169 +- 0.018       49.5 +-28.5      181 vector_180\n",
            " 0.198 +- 0.055       52   +-50        125 vector_124\n",
            " 0.165 +- 0.015       52.5 +-28.5      128 vector_127\n",
            " 0.162 +- 0.004       53.5 +-11.5       76 vector_75\n",
            " 0.161 +- 0.005       54   +-10        240 vector_239\n",
            " 0.162 +- 0.009       54.5 +-18.5       67 vector_66\n",
            " 0.161 +- 0.004       55   +- 8         28 vector_27\n",
            " 0.16  +- 0.003       56   +- 6        207 vector_206\n",
            " 0.162 +- 0.01        57   +-23        257 vector_256\n",
            " 0.16  +- 0           59   +- 3        143 vector_142\n",
            " 0.159 +- 0.006       59.5 +-14.5      275 vector_274\n",
            " 0.159 +- 0.004       59.5 +-10.5      251 vector_250\n",
            " 0.159 +- 0.003       60   +- 9         77 vector_76\n",
            " 0.158 +- 0.003       61.5 +- 6.5       12 vector_11\n",
            " 0.159 +- 0.008       62   +-20         79 vector_78\n",
            " 0.161 +- 0.017       62.5 +-37.5       24 vector_23\n",
            " 0.16  +- 0.013       63   +-30        159 vector_158\n",
            " 0.159 +- 0.007       63.5 +-17.5      101 vector_100\n",
            " 0.157 +- 0.005       65   +-13        278 vector_277\n",
            " 0.156 +- 0.002       66.5 +- 5.5      220 vector_219\n",
            " 0.159 +- 0.017       67   +-38        273 vector_272\n",
            " 0.156 +- 0.003       67.5 +- 7.5       38 vector_37\n",
            " 0.155 +- 0.003       68   +- 8        175 vector_174\n",
            " 0.156 +- 0.008       69   +-20         65 vector_64\n",
            " 0.156 +- 0.01        69   +-26         31 vector_30\n",
            " 0.157 +- 0.012       70   +-31         86 vector_85\n",
            " 0.154 +- 0.004       70.5 +-11.5        2 vector_1\n",
            " 0.153 +- 0.006       73   +-16        113 vector_112\n",
            " 0.152 +- 0.002       74   +- 5        165 vector_164\n",
            " 0.152 +- 0           75.5 +- 0.5       41 vector_40\n",
            " 0.151 +- 0.003       77.5 +-10.5      213 vector_212\n",
            " 0.153 +- 0.01        77.5 +-26.5      295 vector_294\n",
            " 0.151 +- 0.002       78   +- 6         71 vector_70\n",
            " 0.151 +- 0.002       79.5 +- 5.5      126 vector_125\n",
            " 0.166 +- 0.034       81   +-69        166 vector_165\n",
            " 0.151 +- 0.008       81   +-22         23 vector_22\n",
            " 0.151 +- 0.011       82   +-30        269 vector_268\n",
            " 0.15  +- 0.002       82.5 +- 3.5       57 vector_56\n",
            " 0.15  +- 0.014       87.5 +-41.5      118 vector_117\n",
            " 0.153 +- 0.02        87.5 +-53.5       36 vector_35\n",
            " 0.149 +- 0.008       88.5 +-20.5        4 vector_3\n",
            " 0.148 +- 0           89   +- 1         51 vector_50\n",
            " 0.148 +- 0.012       89.5 +-36.5      232 vector_231\n",
            " 0.149 +- 0.011       93.5 +-32.5      282 vector_281\n",
            " 0.148 +- 0.009       93.5 +-26.5       10 vector_9\n",
            " 0.149 +- 0.01        93.5 +-29.5      231 vector_230\n",
            " 0.147 +- 0.008       93.5 +-27.5      249 vector_248\n",
            " 0.149 +- 0.024       95   +-63        212 vector_211\n",
            " 0.146 +- 0.007       95.5 +-24.5      139 vector_138\n",
            " 0.146 +- 0.001       96   +- 4        146 vector_145\n",
            " 0.149 +- 0.017       96.5 +-52.5      245 vector_244\n",
            " 0.146 +- 0.005       97.5 +-13.5       78 vector_77\n",
            " 0.146 +- 0.006       97.5 +-20.5        7 vector_6\n",
            " 0.145 +- 0.003       97.5 +-11.5       15 vector_14\n",
            " 0.145 +- 0.002       98.5 +- 7.5       52 vector_51\n",
            " 0.145 +- 0.002       99   +- 5         18 vector_17\n",
            " 0.145 +- 0.005       99   +-16         73 vector_72\n",
            " 0.146 +- 0.008       99   +-28        161 vector_160\n",
            " 0.145 +- 0.001       99.5 +- 2.5      301 vector_300\n",
            " 0.146 +- 0.013      103   +-40        226 vector_225\n",
            " 0.144 +- 0.011      104   +-39        123 vector_122\n",
            " 0.143 +- 0.001      104.5 +- 1.5      119 vector_118\n",
            " 0.143 +- 0.002      105.5 +- 6.5      137 vector_136\n",
            " 0.143 +- 0.003      107   +-12         21 vector_20\n",
            " 0.142 +- 0.002      108.5 +- 9.5       81 vector_80\n",
            " 0.142 +- 0.008      110.5 +-30.5      176 vector_175\n",
            " 0.142 +- 0.001      110.5 +- 2.5       95 vector_94\n",
            " 0.142 +- 0.001      110.5 +- 3.5       94 vector_93\n",
            " 0.141 +- 0.007      113   +-23        107 vector_106\n",
            " 0.14  +- 0.001      114   +- 3         46 vector_45\n",
            " 0.142 +- 0.009      114   +-31        186 vector_185\n",
            " 0.141 +- 0.008      114.5 +-27.5      144 vector_143\n",
            " 0.142 +- 0.011      114.5 +-37.5      253 vector_252\n",
            " 0.142 +- 0.011      114.5 +-41.5      133 vector_132\n",
            " 0.14  +- 0.006      115.5 +-19.5      150 vector_149\n",
            " 0.14  +- 0          116   +- 0        145 vector_144\n",
            " 0.14  +- 0.006      116   +-22         62 vector_61\n",
            " 0.14  +- 0.009      117   +-30        265 vector_264\n",
            " 0.138 +- 0.006      124.5 +-26.5      209 vector_208\n",
            " 0.137 +- 0.009      125   +-28        116 vector_115\n",
            " 0.137 +- 0.003      127   +-13        262 vector_261\n",
            " 0.137 +- 0.002      127   +- 6        281 vector_280\n",
            " 0.079 +- 0.079      129   +-63        296 vector_295\n",
            " 0.136 +- 0.004      129.5 +-16.5      177 vector_176\n",
            " 0.136 +- 0.002      130.5 +- 8.5      135 vector_134\n",
            " 0.077 +- 0.077      132   +-62         61 vector_60\n",
            " 0.073 +- 0.073      136.5 +-43.5       27 vector_26\n",
            " 0.072 +- 0.072      137   +-32         72 vector_71\n",
            " 0.135 +- 0.005      137   +-20        203 vector_202\n",
            " 0.134 +- 0.001      140   +- 7        284 vector_283\n",
            " 0.134 +- 0.005      141   +-19         68 vector_67\n",
            " 0.133 +- 0.003      143.5 +-15.5       55 vector_54\n",
            " 0.133 +- 0.003      143.5 +-11.5      248 vector_247\n",
            " 0.133 +- 0.005      144.5 +-19.5      290 vector_289\n",
            " 0.132 +- 0          145   +- 3        194 vector_193\n",
            " 0.068 +- 0.068      145   +-21        259 vector_258\n",
            " 0.133 +- 0.002      145.5 +- 8.5      110 vector_109\n",
            " 0.071 +- 0.071      146.5 +-36.5       69 vector_68\n",
            " 0.073 +- 0.073      147.5 +-49.5       50 vector_49\n",
            " 0.131 +- 0.007      148   +-24         93 vector_92\n",
            " 0.067 +- 0.067      151   +-14         82 vector_81\n",
            " 0.068 +- 0.068      151   +-26        291 vector_290\n",
            " 0.131 +- 0.005      151.5 +-17.5      122 vector_121\n",
            " 0.13  +- 0          153.5 +- 4.5        9 vector_8\n",
            " 0.073 +- 0.073      155   +-59        222 vector_221\n",
            " 0.13  +- 0.003      156   +-12        246 vector_245\n",
            " 0.071 +- 0.071      157.5 +-47.5       85 vector_84\n",
            " 0.067 +- 0.067      161   +-21         29 vector_28\n",
            " 0.07  +- 0.07       161.5 +-46.5       39 vector_38\n",
            " 0.072 +- 0.072      163.5 +-62.5       26 vector_25\n",
            " 0.064 +- 0.064      165.5 +-13.5       48 vector_47\n",
            " 0.067 +- 0.067      166   +-35        274 vector_273\n",
            " 0.063 +- 0.063      166.5 +- 3.5      261 vector_260\n",
            " 0.124 +- 0          166.5 +- 7.5      138 vector_137\n",
            " 0.065 +- 0.065      166.5 +-15.5      258 vector_257\n",
            " 0.068 +- 0.068      169   +-40          5 vector_4\n",
            " 0.064 +- 0.064      172   +- 6         33 vector_32\n",
            " 0     +- 0          173.5 +-11.5       64 vector_63\n",
            " 0     +- 0          174   +- 4        264 vector_263\n",
            " 0.062 +- 0.062      174   +-17         63 vector_62\n",
            " 0     +- 0          177   +-10         60 vector_59\n",
            " 0.074 +- 0.074      177   +-85        243 vector_242\n",
            " 0.058 +- 0.058      178   +-18        199 vector_198\n",
            " 0     +- 0          179.5 +- 4.5      268 vector_267\n",
            " 0.066 +- 0.066      180   +-27         45 vector_44\n",
            " 0     +- 0          180.5 +- 7.5      266 vector_265\n",
            " 0.067 +- 0.067      181   +-42        171 vector_170\n",
            " 0     +- 0          182   +-10        263 vector_262\n",
            " 0     +- 0          186   +-10         58 vector_57\n",
            " 0.069 +- 0.069      186.5 +-63.5      190 vector_189\n",
            " 0.067 +- 0.067      188.5 +-52.5      239 vector_238\n",
            " 0     +- 0          189   +- 8        288 vector_287\n",
            " 0.071 +- 0.071      189   +-82        187 vector_186\n",
            " 0     +- 0          189.5 +-12.5       54 vector_53\n",
            " 0     +- 0          189.5 +-15.5      204 vector_203\n",
            " 0     +- 0          190   +-26        256 vector_255\n",
            " 0.069 +- 0.069      190   +-71        108 vector_107\n",
            " 0.068 +- 0.068      190.5 +-60.5      183 vector_182\n",
            " 0.068 +- 0.068      191   +-63        211 vector_210\n",
            " 0.074 +- 0.074      191   +-106     184 vector_183\n",
            " 0     +- 0          191.5 +-11.5       56 vector_55\n",
            " 0.065 +- 0.065      192   +-42        228 vector_227\n",
            " 0.071 +- 0.071      192.5 +-84.5       80 vector_79\n",
            " 0     +- 0          193   +- 8         17 vector_16\n",
            " 0     +- 0          193   +- 7         16 vector_15\n",
            " 0.067 +- 0.067      193.5 +-58.5      180 vector_179\n",
            " 0     +- 0          193.5 +-12.5       47 vector_46\n",
            " 0.067 +- 0.067      194   +-62        210 vector_209\n",
            " 0     +- 0          194.5 +- 3.5       14 vector_13\n",
            " 0     +- 0          194.5 +-18.5       22 vector_21\n",
            " 0.074 +- 0.074      195.5 +-104.5     151 vector_150\n",
            " 0     +- 0          196.5 +- 9.5        8 vector_7\n",
            " 0     +- 0          197   +- 7         11 vector_10\n",
            " 0     +- 0          197   +-13        293 vector_292\n",
            " 0     +- 0          197.5 +- 9.5        3 vector_2\n",
            " 0     +- 0          197.5 +-14.5      286 vector_285\n",
            " 0     +- 0          198   +- 5         13 vector_12\n",
            " 0.068 +- 0.068      198.5 +-71.5      104 vector_103\n",
            " 0     +- 0          198.5 +- 9.5      298 vector_297\n",
            " 0.067 +- 0.067      199.5 +-65.5      242 vector_241\n",
            " 0     +- 0          200.5 +-29.5       70 vector_69\n",
            " 0     +- 0          202   +-23         25 vector_24\n",
            " 0.067 +- 0.067      204.5 +-66.5      102 vector_101\n",
            " 0.064 +- 0.064      204.5 +-41.5      201 vector_200\n",
            " 0.068 +- 0.068      206.5 +-76.5      185 vector_184\n",
            " 0     +- 0          207   +- 8         35 vector_34\n",
            " 0     +- 0          208.5 +-13.5       34 vector_33\n",
            " 0     +- 0          209   +-15         32 vector_31\n",
            " 0.064 +- 0.064      210   +-45        189 vector_188\n",
            " 0     +- 0          211   +- 7        271 vector_270\n",
            " 0.066 +- 0.066      211   +-65        100 vector_99\n",
            " 0.066 +- 0.066      212   +-67         75 vector_74\n",
            " 0     +- 0          213   +-15        279 vector_278\n",
            " 0.063 +- 0.063      213.5 +-58.5       88 vector_87\n",
            " 0     +- 0          214   +-53        255 vector_254\n",
            " 0     +- 0          214   +- 3         40 vector_39\n",
            " 0     +- 0          214.5 +-28.5      197 vector_196\n",
            " 0     +- 0          214.5 +-14.5      277 vector_276\n",
            " 0     +- 0          214.5 +-25.5      196 vector_195\n",
            " 0.068 +- 0.068      215.5 +-84.5      106 vector_105\n",
            " 0     +- 0          215.5 +- 5.5       37 vector_36\n",
            " 0     +- 0          216   +-21        216 vector_215\n",
            " 0     +- 0          216   +- 3         42 vector_41\n",
            " 0     +- 0          216   +- 7        283 vector_282\n",
            " 0.063 +- 0.063      216   +-60        121 vector_120\n",
            " 0.067 +- 0.067      216.5 +-72.5      148 vector_147\n",
            " 0     +- 0          217   +- 3         43 vector_42\n",
            " 0     +- 0          217   +-24        195 vector_194\n",
            " 0     +- 0          217   +-27        198 vector_197\n",
            " 0.062 +- 0.062      219   +-48        114 vector_113\n",
            " 0     +- 0          219.5 +- 7.5      280 vector_279\n",
            " 0.064 +- 0.064      220   +-66         98 vector_97\n",
            " 0.066 +- 0.066      220   +-72        112 vector_111\n",
            " 0     +- 0          220   +-18        214 vector_213\n",
            " 0.065 +- 0.065      222   +-61        140 vector_139\n",
            " 0     +- 0          223   +-55         74 vector_73\n",
            " 0     +- 0          223   +-24        206 vector_205\n",
            " 0.06  +- 0.06       223.5 +-48.5       92 vector_91\n",
            " 0.065 +- 0.065      224.5 +-62.5      229 vector_228\n",
            " 0     +- 0          226   +- 5        169 vector_168\n",
            " 0     +- 0          228   +-17        208 vector_207\n",
            " 0.064 +- 0.064      229.5 +-62.5      233 vector_232\n",
            " 0     +- 0          231   +- 6        173 vector_172\n",
            " 0     +- 0          231   +- 7        172 vector_171\n",
            " 0     +- 0          232.5 +- 0.5      227 vector_226\n",
            " 0.062 +- 0.062      233.5 +-60.5      236 vector_235\n",
            " 0     +- 0          237.5 +-18.5      167 vector_166\n",
            " 0     +- 0          239.5 +-17.5      170 vector_169\n",
            " 0     +- 0          240   +- 8        193 vector_192\n",
            " 0     +- 0          240.5 +-13.5      164 vector_163\n",
            " 0     +- 0          242   +-11        163 vector_162\n",
            " 0     +- 0          243.5 +-25.5      168 vector_167\n",
            " 0     +- 0          244   +- 8        162 vector_161\n",
            " 0     +- 0          244.5 +-29.5       84 vector_83\n",
            " 0     +- 0          245   +-15        154 vector_153\n",
            " 0     +- 0          245.5 +-16.5      155 vector_154\n",
            " 0     +- 0          246.5 +-12.5      158 vector_157\n",
            " 0     +- 0          246.5 +-11.5      160 vector_159\n",
            " 0     +- 0          248   +-15        157 vector_156\n",
            " 0     +- 0          248.5 +-31.5      254 vector_253\n",
            " 0     +- 0          253.5 +-27.5      223 vector_222\n",
            " 0     +- 0          255   +- 5        300 vector_299\n",
            " 0     +- 0          255   +- 4        152 vector_151\n",
            " 0     +- 0          255   +-27        252 vector_251\n",
            " 0     +- 0          255.5 +-39.5      103 vector_102\n",
            " 0     +- 0          256.5 +-36.5      225 vector_224\n",
            " 0     +- 0          258.5 +-23.5      141 vector_140\n",
            " 0     +- 0          259.5 +- 1.5      153 vector_152\n",
            " 0     +- 0          260.5 +-24.5      142 vector_141\n",
            " 0     +- 0          262   +-18        237 vector_236\n",
            " 0     +- 0          262   +-13        191 vector_190\n",
            " 0     +- 0          263.5 +- 6.5      188 vector_187\n",
            " 0     +- 0          264   +- 1        238 vector_237\n",
            " 0     +- 0          264.5 +-25.5      178 vector_177\n",
            " 0     +- 0          264.5 +-25.5      136 vector_135\n",
            " 0     +- 0          265   +-16        149 vector_148\n",
            " 0     +- 0          265.5 +-25.5      134 vector_133\n",
            " 0     +- 0          265.5 +-23.5      179 vector_178\n",
            " 0     +- 0          268   +-20        147 vector_146\n",
            " 0     +- 0          269   +-26        127 vector_126\n",
            " 0     +- 0          269.5 +-27.5      132 vector_131\n",
            " 0     +- 0          270.5 +-15.5      230 vector_229\n",
            " 0     +- 0          270.5 +-25.5      129 vector_128\n",
            " 0     +- 0          270.5 +- 2.5      250 vector_249\n",
            " 0     +- 0          272   +-26        130 vector_129\n",
            " 0     +- 0          273   +-26        131 vector_130\n",
            " 0     +- 0          273.5 +- 0.5      247 vector_246\n",
            " 0     +- 0          275   +- 9        124 vector_123\n",
            " 0     +- 0          275.5 +-22.5      182 vector_181\n",
            " 0     +- 0          277.5 +- 9.5      115 vector_114\n",
            " 0     +- 0          278.5 +-14.5      235 vector_234\n",
            " 0     +- 0          278.5 +-12.5      241 vector_240\n",
            " 0     +- 0          279   +-15        109 vector_108\n",
            " 0     +- 0          279.5 +- 4.5       96 vector_95\n",
            " 0     +- 0          281   +- 4         97 vector_96\n",
            " 0     +- 0          283.5 +- 4.5      117 vector_116\n",
            " 0     +- 0          284   +-15        105 vector_104\n",
            " 0     +- 0          287   +- 9         99 vector_98\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6nrPQaAhwDeB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then remove the lowest ranked 200 attributes, significantly decreasing the size of our features. To make sure that performing Principal Component Analysis by using the InfoGain of the features doesn't decrease the performance of a model trained on this dataset, we evaluate again a tree classifier (Random Forest) trained on only these 100 features, and we see that we achieve good accuracy of 67%."
      ]
    },
    {
      "metadata": {
        "id": "f34uyg6Oukux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "attr = attsel.selected_attributes\n",
        "attr2 = list(range(1, 301))\n",
        "# We want to keep only the 100 top ranked attributes\n",
        "for i in attr[:100]:\n",
        "  attr2.remove(i)\n",
        "attr3 = []\n",
        "for i in attr2:\n",
        "  attr3.append(str(i+1))\n",
        "goo = (\",\".join(attr3))\n",
        "\n",
        "r = Filter(\"weka.filters.unsupervised.attribute.Remove\", options = [\"-R\", goo])\n",
        "r.inputformat(full)\n",
        "filtered = r.filter(full)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0CQ4tRv0uxbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8fce8b67-79b9-4df8-ec03-3974434377ff"
      },
      "cell_type": "code",
      "source": [
        "print('Classifying on: ', filtered.attribute(0))\n",
        "filtered.class_index = 0\n",
        "train, test = filtered.train_test_split(66.0, Random(1))\n",
        "\n",
        "\n",
        "cls = Classifier(classname=\"weka.classifiers.trees.RandomForest\")\n",
        "cls.build_classifier(train)\n",
        "\n",
        "evl = Evaluation(train)\n",
        "evl.test_model(cls, test)\n",
        "print(evl.summary(\"=== Percentage split 66% ===\"))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifying on:  @attribute Class {Super_Bowl_50,Warsaw,Normans,Nikola_Tesla,Computational_complexity_theory,Teacher,Martin_Luther,Southern_California,Sky_(United_Kingdom),Victoria_(Australia),Huguenot,Steam_engine,Oxygen,1973_oil_crisis,Apollo_program,European_Union_law,Amazon_rainforest,Ctenophora,'Fresno,_California',Packet_switching,Black_Death,Geology,Newcastle_upon_Tyne,Victoria_and_Albert_Museum,American_Broadcasting_Company,Genghis_Khan,Pharmacy,Immune_system,Civil_disobedience,Construction}\n",
            "=== Percentage split 66% ===\n",
            "Correctly Classified Instances         713               67.3913 %\n",
            "Incorrectly Classified Instances       345               32.6087 %\n",
            "Kappa statistic                          0.6627\n",
            "Mean absolute error                      0.0491\n",
            "Root mean squared error                  0.1453\n",
            "Relative absolute error                 76.1026 %\n",
            "Root relative squared error             80.9465 %\n",
            "Total Number of Instances             1058     \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dyQkZKSjIXcH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clustering\n",
        "\n",
        "In this section and in order to successfully perform clustering and evaluate the results against our classes, Google Colab could only handle smaller dataset, so we had to reduce the number of samples and desired clusters (number of classes in the initial dataset). We will again perform attribute selection and then apply SimpleKMeans clustering."
      ]
    },
    {
      "metadata": {
        "id": "4Y0uWR2YIPUo",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d116d27e-b726-4b31-e278-5527cd80c9ec"
      },
      "cell_type": "code",
      "source": [
        "# Choose from your own machine the files to upload - name should be \n",
        "# \"squad_vectors_reduced.csv\"\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3983f7a6-3007-4385-a54f-ec9becfdcec1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3983f7a6-3007-4385-a54f-ec9becfdcec1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving squad_vectors_reduced.csv to squad_vectors_reduced.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VJVYCdHlIy_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_file = 'squad_vectors_reduced.csv'\n",
        "full = loader.load_file(data_file)\n",
        "full.class_index = 0\n",
        "search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"100\"])\n",
        "evaluation = ASEvaluation(\"weka.attributeSelection.InfoGainAttributeEval\")\n",
        "attsel = AttributeSelection()\n",
        "attsel.ranking(True)\n",
        "attsel.folds(2)\n",
        "attsel.crossvalidation(True)\n",
        "attsel.seed(42)\n",
        "attsel.search(search)\n",
        "attsel.evaluator(evaluation)\n",
        "attsel.select_attributes(full)\n",
        "\n",
        "attr = attsel.selected_attributes\n",
        "attr2 = list(range(1, 301))\n",
        "# We want to keep only the 100 top ranked attributes\n",
        "for i in attr[:100]:\n",
        "  attr2.remove(i)\n",
        "attr3 = []\n",
        "for i in attr2:\n",
        "  attr3.append(str(i+1))\n",
        "goo = (\",\".join(attr3))\n",
        "\n",
        "r = Filter(\"weka.filters.unsupervised.attribute.Remove\", options = [\"-R\", goo])\n",
        "r.inputformat(full)\n",
        "filtered = r.filter(full)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2gVyZ4peKlnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2723
        },
        "outputId": "440d28a9-4830-483b-a657-3a7b11233eef"
      },
      "cell_type": "code",
      "source": [
        "full = Instances.copy_instances(filtered)\n",
        "data = Instances.copy_instances(filtered)\n",
        "data.no_class()\n",
        "data.delete_attribute(0)\n",
        "\n",
        "\n",
        "clusterer = Clusterer(classname=\"weka.clusterers.SimpleKMeans\", options=[\"-N\", \"6\"])\n",
        "clusterer.build_clusterer(data)\n",
        "\n",
        "# classes to clusters\n",
        "evl = ClusterEvaluation()\n",
        "evl.set_model(clusterer)\n",
        "evl.test_model(full)\n",
        "print(\"Cluster results\")\n",
        "print(evl.cluster_results)\n",
        "print(\"Classes to clusters\")\n",
        "print(evl.classes_to_clusters)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster results\n",
            "\n",
            "kMeans\n",
            "======\n",
            "\n",
            "Number of iterations: 31\n",
            "Within cluster sum of squared errors: 966.297534874898\n",
            "\n",
            "Initial starting points (random):\n",
            "\n",
            "Cluster 0: 0.147448,0.197533,-0.044818,1.066038,-0.524173,0.390865,0.094538,0.357294,-0.180145,-0.014014,-0.156085,-0.1754,0.403217,-0.137324,-0.00115,0.064803,-0.16955,0.240462,-0.080003,-0.009862,0.182377,-0.012749,-0.173015,0.05764,0.070989,-0.083744,-0.190712,0.171715,-0.194349,0.112126,0.032233,0.124618,-0.293527,-0.091996,-0.943734,-0.063402,-0.048336,-0.163679,0.098866,0.020664,-0.144495,-0.091228,0.232769,0.123182,-0.061444,0.058062,0.01416,0.194798,-0.000054,-0.171339,-0.034409,0.242292,0.345444,0.081944,0.193546,0.113629,0.085784,-0.146271,-0.073855,0.039765,-0.083515,0.138332,0.057803,0.026438,0.115902,0.07499,0.0182,-0.046944,-0.018517,0.074831,0.025846,-0.136665,0.143654,-0.010292,0.174061,-0.20188,-0.152503,0.068272,-0.023235,-0.098519,0.056706,0.165668,-0.088316,-0.161943,-0.210242,-0.064989,-0.2291,-0.049827,-0.371325,0.251394,-0.029629,0.157732,-0.138589,0.06046,0.019496,0.215608,0.014828,-0.057486,-0.019756,0.095353\n",
            "Cluster 1: 0.23548,-0.156541,-0.115289,-0.318415,-0.032257,0.033015,0.111063,0.65716,-0.029481,-0.255162,-0.24364,0.06463,0.374255,-0.11457,0.213765,0.050187,0.328563,0.20909,-0.071731,0.11809,-0.152388,0.011316,0.054287,0.152406,0.372468,-0.161253,-0.20704,-0.134376,-0.024144,-0.134128,-0.141167,0.180389,-0.118538,-0.304781,-1.121533,-0.013337,-0.267847,-0.118632,0.031197,0.129868,-0.387043,0.132529,0.018889,-0.066609,0.056007,-0.152388,-0.01199,0.097111,0.27453,-0.166322,-0.096054,0.053524,0.17222,0.316913,0.122708,0.053768,-0.05881,-0.227563,0.395662,-0.163507,0.008348,0.233885,-0.32609,-0.272804,-0.042328,0.100637,-0.28433,-0.073303,-0.123377,-0.025135,0.056239,-0.023668,-0.051065,0.125937,-0.102378,-0.338787,0.167726,-0.03884,-0.17074,-0.049007,0.146309,0.177093,0.119509,-0.279368,-0.238055,0.05765,-0.001362,0.163437,-0.401647,0.333638,0.163652,0.154892,-0.348085,-0.320362,-0.096405,0.233907,0.261007,-0.123158,-0.152906,0.362555\n",
            "Cluster 2: -0.01384,0.037819,-0.154163,1.263147,-0.380405,0.392043,0.147288,0.017766,0.07993,0.116949,-0.009223,-0.084362,0.364307,-0.014866,0.107676,-0.125603,-0.289918,0.187283,-0.043758,-0.071366,-0.115797,0.135578,-0.220508,-0.134594,-0.137394,-0.035434,0.063803,0.044249,-0.262834,0.191831,0.09151,-0.17896,-0.145664,0.011369,-1.104375,-0.232728,-0.08214,-0.108295,-0.175835,-0.214018,-0.024902,-0.228751,0.151698,0.107295,0.06909,0.22694,-0.028778,0.10016,0.132958,-0.211052,-0.016434,0.007412,0.292725,0.183022,-0.170889,0.149312,0.014391,0.038007,0.210337,-0.028502,-0.343432,-0.057599,-0.036427,0.273673,0.15638,0.229598,0.089613,-0.053686,-0.192535,-0.097128,-0.060948,0.057351,0.228437,0.226918,0.009218,0.110315,-0.044248,0.113149,0.053531,-0.078086,0.191145,0.094227,-0.179597,0.041905,0.231667,0.138498,-0.205023,0.065769,0.263855,0.047932,-0.120843,0.073785,-0.063553,-0.038002,-0.175802,-0.031395,-0.107453,-0.082508,0.109775,0.111632\n",
            "Cluster 3: 0.080817,0.018993,0.24473,1.297608,-0.192657,0.876163,-0.006656,0.050601,-0.040814,0.045247,-0.16883,-0.169571,-0.048255,0.039592,-0.090624,-0.054867,-0.035654,0.023096,0.050896,-0.222972,-0.025248,0.016052,-0.056001,0.124419,-0.003549,0.062154,0.126483,0.115549,0.039523,-0.07923,0.026664,-0.169112,0.176014,-0.07311,-0.560618,0.022611,0.17002,-0.00079,-0.06389,-0.049537,0.119293,-0.014826,-0.089856,-0.000048,0.039642,0.140707,0.019184,-0.115238,-0.114758,0.035642,0.00801,-0.138333,0.073005,0.025069,-0.170248,-0.077356,0.078321,0.02903,-0.020722,-0.006093,-0.029723,-0.088367,0.043516,0.167155,-0.035375,-0.042307,-0.148671,0.002176,0.175258,-0.068331,-0.129956,-0.221146,-0.097308,0.114465,0.301847,-0.04481,-0.055563,-0.157135,0.045855,0.013693,-0.055806,-0.093378,-0.073973,-0.148098,0.001253,0.041177,-0.055241,-0.040729,0.334787,-0.001183,-0.038617,-0.129107,0.102983,0.01708,-0.022561,-0.0598,0.006498,0.0544,-0.193154,0.107168\n",
            "Cluster 4: 0.359337,-0.19909,0.085506,0.619082,-0.114928,0.482688,-0.070695,0.566425,-0.025284,-0.154567,-0.147814,0.077641,0.186863,-0.16064,0.06758,0.164388,0.2702,0.04715,0.089617,0.063765,-0.020208,0.017698,-0.067493,0.068667,0.226226,-0.19378,-0.184347,-0.143098,0.093852,0.016902,0.02818,0.25636,-0.480998,-0.20075,-0.786945,0.105443,-0.235172,-0.073842,-0.151677,0.205775,-0.288674,0.163109,-0.07071,-0.120741,-0.12922,-0.003982,0.009222,0.13499,0.284068,-0.128185,-0.08547,0.091684,0.208792,0.208312,-0.040048,-0.105268,-0.042483,0.033005,0.381097,-0.153304,-0.115868,0.134523,-0.008921,-0.217625,-0.167192,0.023683,-0.13522,-0.115803,-0.03734,-0.088282,-0.098039,-0.02799,-0.19508,0.165669,-0.12174,-0.370815,0.038591,-0.032858,-0.082848,0.176798,0.319765,0.172255,-0.043432,-0.300465,-0.277833,-0.096908,0.053155,0.158526,-0.21848,0.353102,0.1908,0.047091,-0.028497,-0.000135,-0.081677,0.096445,0.157069,-0.051675,-0.204268,0.252832\n",
            "Cluster 5: 0.36035,0.034596,-0.042372,1.620992,-0.174461,0.505264,-0.142863,0.229225,-0.046804,-0.064677,-0.016254,0.061047,0.034237,0.087063,0.131849,0.134588,0.127822,-0.009539,0.016951,0.040281,-0.048031,0.066375,0.021851,-0.043264,0.039169,-0.070276,0.020341,-0.08664,0.007735,0.012578,0.052229,-0.156798,-0.318751,-0.220853,-0.533011,-0.034172,-0.175618,0.025347,-0.053234,0.078022,-0.157083,0.100427,-0.065493,-0.083268,-0.038068,0.079814,-0.048636,-0.099562,0.265544,-0.170619,-0.035118,0.042282,0.09582,-0.117729,0.034411,-0.02253,-0.143402,0.009985,-0.003164,-0.10158,-0.119551,0.131468,0.096737,-0.096308,-0.029142,-0.051991,-0.14902,-0.09809,0.000212,-0.042178,0.017647,-0.221454,-0.120731,0.024074,0.043024,-0.193343,-0.04427,-0.060428,0.049803,0.099351,0.113305,-0.087133,-0.072335,-0.087966,0.010455,-0.041891,0.057084,0.073898,0.153888,0.210165,-0.165203,-0.048337,-0.00246,-0.091692,-0.11067,0.011174,0.042055,-0.064089,-0.107634,0.094308\n",
            "\n",
            "Missing values globally replaced with mean/mode\n",
            "\n",
            "Final cluster centroids:\n",
            "                          Cluster#\n",
            "Attribute     Full Data          0          1          2          3          4          5\n",
            "                (625.0)     (80.0)     (55.0)      (1.0)     (93.0)    (216.0)    (180.0)\n",
            "=========================================================================================\n",
            "vector_2         0.1518     0.1183     0.2947    -0.0138     0.0914     0.1369     0.1731\n",
            "vector_5         0.0403     0.1976    -0.2059     0.0378     0.0857     0.0453     0.0161\n",
            "vector_9         0.0207    -0.0079      -0.06    -0.1542     0.1608    -0.0142     0.0284\n",
            "vector_10        1.3861     0.9619     0.4984     1.2631     1.3694     1.5215     1.6927\n",
            "vector_11        -0.163    -0.3672     0.1139    -0.3804    -0.2029    -0.1449    -0.1566\n",
            "vector_18        0.5941     0.3702     0.3367      0.392     0.5449      0.446     0.9766\n",
            "vector_19       -0.0704     0.0668    -0.0942     0.1473     0.0094    -0.0775    -0.1579\n",
            "vector_21        0.1266     0.1355     0.4832     0.0178     0.0282     0.1202     0.0727\n",
            "vector_22       -0.0846    -0.0139    -0.0499     0.0799    -0.0801    -0.0818    -0.1333\n",
            "vector_24       -0.0439    -0.0551    -0.1341     0.1169    -0.1159     -0.032     0.0108\n",
            "vector_27       -0.0402    -0.1999    -0.0709    -0.0092    -0.1183    -0.0225     0.0592\n",
            "vector_29        0.0173    -0.1416      0.121    -0.0844     0.0233     0.0064     0.0668\n",
            "vector_30        0.0703     0.2808     0.2389     0.3643    -0.0355     0.0724    -0.0243\n",
            "vector_32        0.0763     0.0194    -0.1297    -0.0149     0.0164     0.1133     0.1515\n",
            "vector_35        0.0892     0.0322     0.2311     0.1077     0.0069     0.0696     0.1371\n",
            "vector_37         0.043     0.0193     0.1137    -0.1256    -0.0151     0.0015     0.1128\n",
            "vector_38        0.0149    -0.0122     0.2626    -0.2899    -0.0743    -0.0083     0.0269\n",
            "vector_40       -0.0414     0.0451     0.1132     0.1873    -0.0416    -0.0273     -0.145\n",
            "vector_43       -0.0068    -0.0036     -0.012    -0.0438     0.0769     0.0132    -0.0737\n",
            "vector_49        0.0137     0.0801     0.0313    -0.0714     -0.132     0.0441     0.0181\n",
            "vector_50        0.0112     0.0132     -0.088    -0.1158     0.0409     0.0194     0.0161\n",
            "vector_52        0.0148    -0.0254    -0.0214     0.1356    -0.0392    -0.0012       0.09\n",
            "vector_54       -0.0025    -0.0403     0.0245    -0.2205    -0.1296     0.0143     0.0528\n",
            "vector_58        0.0208    -0.0475     0.1285    -0.1346     0.1809    -0.0169    -0.0185\n",
            "vector_63         0.054      0.064     0.2401    -0.1374     0.0324     0.0424      0.019\n",
            "vector_67       -0.0551    -0.0775    -0.1651    -0.0354     0.0383    -0.0562    -0.0586\n",
            "vector_71        0.0047     0.0115    -0.1764     0.0638     0.0756    -0.0209      0.051\n",
            "vector_72       -0.0474    -0.0184    -0.1752     0.0442     0.0671    -0.0509    -0.0769\n",
            "vector_77        0.0037    -0.1549     0.0319    -0.2628    -0.0277     0.0242     0.0587\n",
            "vector_81       -0.0107     0.0047    -0.1684     0.1918    -0.0234     0.0241    -0.0055\n",
            "vector_85        0.0077    -0.1083    -0.0174     0.0915     -0.026     0.0324     0.0543\n",
            "vector_87       -0.0442     0.1823     0.0569     -0.179     0.0695    -0.0589     -0.216\n",
            "vector_88       -0.1212    -0.1246    -0.2438    -0.1457     0.0863    -0.1746    -0.1252\n",
            "vector_93       -0.1126    -0.1073    -0.2772     0.0114    -0.0735    -0.0778    -0.1274\n",
            "vector_106      -0.7197    -0.7517    -0.7676    -1.1044    -0.5192    -0.5931    -0.9443\n",
            "vector_108       0.0218    -0.0088     0.0889    -0.2327    -0.0513      0.022      0.054\n",
            "vector_109      -0.0563    -0.0916    -0.2798    -0.0821     0.1163    -0.0358    -0.0857\n",
            "vector_110      -0.0402    -0.1457    -0.0692    -0.1083    -0.0611    -0.0441     0.0315\n",
            "vector_112      -0.0526     0.0228     -0.032    -0.1758    -0.1883     0.0018    -0.0869\n",
            "vector_113       0.0244     0.0223     0.2102     -0.214    -0.0386     0.0118     0.0176\n",
            "vector_114      -0.0986    -0.1646    -0.3119    -0.0249    -0.0248    -0.0745    -0.0716\n",
            "vector_115       0.0243     -0.033     0.1601    -0.2288    -0.0152     0.0307     0.0224\n",
            "vector_117      -0.0092     0.2405     -0.125     0.1517    -0.0667     0.0154    -0.0855\n",
            "vector_122       -0.055     0.0744    -0.0524     0.1073     -0.011    -0.0569    -0.1348\n",
            "vector_132        -0.01    -0.1824     0.0803     0.0691    -0.0648     0.0041       0.05\n",
            "vector_143       0.0493     0.0195     0.0552     0.2269     0.2071     0.0362     -0.006\n",
            "vector_145       0.0208     0.0691    -0.0449    -0.0288     0.1326     0.0017    -0.0152\n",
            "vector_146      -0.0432     0.0813     0.1097     0.1002    -0.1061    -0.0359    -0.1224\n",
            "vector_148       0.0733     0.1139     0.2585      0.133      0.071     0.0705     0.0029\n",
            "vector_149      -0.0588          0    -0.0928    -0.2111     0.0332    -0.0991    -0.0729\n",
            "vector_150      -0.0516    -0.0208    -0.1467    -0.0164    -0.0522    -0.0761    -0.0066\n",
            "vector_151      -0.0017     0.0095     0.1488     0.0074    -0.0793     0.0085    -0.0248\n",
            "vector_160      -0.0005     0.1117     0.1282     0.2927      0.005    -0.0035    -0.0904\n",
            "vector_161      -0.0288     0.0291     0.1795      0.183     0.0177    -0.0355    -0.1354\n",
            "vector_165       0.0294     0.1777     0.0255    -0.1709     0.0435     0.0524     -0.069\n",
            "vector_173       0.0589     0.0039     0.0357     0.1493    -0.0328     0.0557     0.1412\n",
            "vector_174      -0.0742     0.0397    -0.1331     0.0144    -0.0255     -0.084    -0.1206\n",
            "vector_176        0.018     0.0728    -0.1107      0.038     -0.039     0.0301     0.0478\n",
            "vector_182       0.0087    -0.0501     0.2731     0.2103    -0.0086     0.0018    -0.0297\n",
            "vector_185      -0.0367     0.0873     -0.195    -0.0285     0.0108    -0.0394    -0.0647\n",
            "vector_188      -0.0167     -0.091    -0.0687    -0.3434     0.0102    -0.0103     0.0123\n",
            "vector_199       0.0577     0.1633     0.0801    -0.0576     0.0156     0.0598     0.0237\n",
            "vector_200       0.0496    -0.0569    -0.0866    -0.0364     0.0383     0.0611      0.131\n",
            "vector_201      -0.0164     0.0201    -0.1456     0.2737     0.0624    -0.0207    -0.0304\n",
            "vector_202      -0.0452    -0.0693    -0.1035     0.1564    -0.0968     0.0001    -0.0457\n",
            "vector_203      -0.0348     0.1056     0.0036     0.2296    -0.0267    -0.0323    -0.1176\n",
            "vector_211      -0.0979    -0.0218    -0.2288     0.0896    -0.0579      -0.07    -0.1468\n",
            "vector_214      -0.0738    -0.0783     -0.075    -0.0537     0.0083    -0.0386    -0.1563\n",
            "vector_216       0.0413     0.0059    -0.0825    -0.1925     0.2258     0.0174     0.0295\n",
            "vector_217      -0.0664     0.0186     0.0503    -0.0971    -0.0652    -0.0682    -0.1383\n",
            "vector_218        0.017     0.0063     0.0214    -0.0609    -0.0639     -0.001     0.0843\n",
            "vector_219      -0.1047     0.0262    -0.0269     0.0574    -0.1677    -0.0841    -0.1799\n",
            "vector_223      -0.0159      0.126     -0.124     0.2284    -0.0659    -0.0047    -0.0347\n",
            "vector_227       0.0237      -0.01     0.1806     0.2269    -0.0225     0.0124     0.0271\n",
            "vector_230       0.0366     0.0766    -0.0882     0.0092     0.1169     0.0268     0.0274\n",
            "vector_235      -0.1479     -0.045    -0.3128     0.1103    -0.2146    -0.1289    -0.1331\n",
            "vector_238       0.0119    -0.0821     0.1833    -0.0442     0.0119    -0.0132     0.0317\n",
            "vector_239      -0.0621     0.0121    -0.0308     0.1131    -0.1174    -0.0424    -0.1007\n",
            "vector_243       0.0443     0.0234    -0.0857     0.0535     0.0484     0.0447     0.0909\n",
            "vector_244       0.0063    -0.1349      0.089    -0.0781     0.0821     0.0118    -0.0014\n",
            "vector_247       0.0122     0.0852     0.0796     0.1911    -0.0583    -0.0002     0.0096\n",
            "vector_248      -0.0381     0.0509     0.0389     0.0942    -0.0299    -0.0268    -0.1198\n",
            "vector_249      -0.0755    -0.0101     -0.009    -0.1796    -0.1072    -0.0997     -0.079\n",
            "vector_250      -0.0659      -0.21    -0.2327     0.0419     0.0266    -0.0603    -0.0059\n",
            "vector_257      -0.0182    -0.0407    -0.2054     0.2317    -0.0656    -0.0132     0.0661\n",
            "vector_258       -0.016    -0.0485     0.0158     0.1385     0.0929    -0.0207    -0.0629\n",
            "vector_259        0.044    -0.0424     0.0722     -0.205    -0.0262     0.0486     0.1061\n",
            "vector_268       0.0156    -0.0662     0.1473     0.0658     -0.049    -0.0101     0.0755\n",
            "vector_269       0.1215    -0.2046    -0.1254     0.2639     0.0094     0.0793     0.4498\n",
            "vector_270       0.0869     0.1343     0.2945     0.0479      0.069     0.0606     0.0436\n",
            "vector_274      -0.0844     0.0049     0.0398    -0.1208    -0.0788    -0.0523    -0.2034\n",
            "vector_275      -0.0286     0.1074     0.0095     0.0738    -0.0252    -0.0183    -0.1155\n",
            "vector_280       0.0342    -0.0413    -0.1152    -0.0636     0.0227     0.0373     0.1162\n",
            "vector_281      -0.0119    -0.0053    -0.1995     -0.038    -0.0204     0.0044     0.0275\n",
            "vector_283      -0.0654    -0.0807    -0.1114    -0.1758    -0.2299    -0.0416     0.0126\n",
            "vector_286      -0.0204     0.0882     0.1801    -0.0314     0.0073    -0.0133    -0.1525\n",
            "vector_293         0.02      0.011     0.2287    -0.1075    -0.0275    -0.0045     0.0151\n",
            "vector_294      -0.0161    -0.0044    -0.1758    -0.0825    -0.0139    -0.0285     0.0418\n",
            "vector_296      -0.0189    -0.0036    -0.1273     0.1098    -0.0021    -0.0201    -0.0004\n",
            "vector_300       0.0531     0.1434     0.2106     0.1116    -0.0375    -0.0002     0.0752\n",
            "\n",
            "\n",
            "Clustered Instances\n",
            "\n",
            "0       80 ( 13%)\n",
            "1       55 (  9%)\n",
            "2        1 (  0%)\n",
            "3       93 ( 15%)\n",
            "4      216 ( 35%)\n",
            "5      180 ( 29%)\n",
            "\n",
            "\n",
            "Class attribute: Class\n",
            "Classes to Clusters:\n",
            "\n",
            "   0   1   2   3   4   5  <-- assigned to cluster\n",
            "   0   0   0  93  11   2 | Super_Bowl_50\n",
            "  49   0   0   0  53   2 | Warsaw\n",
            "  29   0   1   0  71   0 | Normans\n",
            "   1  55   0   0  46   6 | Nikola_Tesla\n",
            "   1   0   0   0   2 100 | Computational_complexity_theory\n",
            "   0   0   0   0  33  70 | Teacher\n",
            "\n",
            "Cluster 0 <-- Warsaw\n",
            "Cluster 1 <-- Nikola_Tesla\n",
            "Cluster 2 <-- No class\n",
            "Cluster 3 <-- Super_Bowl_50\n",
            "Cluster 4 <-- Normans\n",
            "Cluster 5 <-- Computational_complexity_theory\n",
            "\n",
            "Incorrectly clustered instances :\t257.0\t 41.12   %\n",
            "\n",
            "Classes to clusters\n",
            "[ 1  3 -1  0  2  4]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}